---
title: 基于数据的工艺优化：现实的做法是什么
subtitle: Mauris blandit aliquet elit, eget tincidunt nibh dolor sit amet,
image: "/images/posts/post-6.png"
author: 郭朝晖
date: 2024-05-05T05:00:00Z
categories: ["数字化转型"]
featured: false
draft: false
---

谈到大数据，人们就会提到：可以通过数据分析可以建立模型，用于生产工艺的优化。这句话原则上是对的，但却容易产生误解或误导、夸大数据分析的作用。

在现代化工业企业中，关键的工艺参数往往都是被标准化的。这些标准是根据多方面的知识综合性地给出的。比如，要考虑安全性、成本、效率、质量等多方面的因素，经常还要采用一些实验的手段。工艺制度的改变，一般需要通过专业人士的确认，甚至要经过适当管理流程的审批，不是随便改的。换句话说：即便模型认为某个参数的改变有利于产品质量，我们也不敢随便授权模型去改、甚至不能授权操作工去改。

日常生产时，实际的工艺参数往往是围绕着标准值波动的。如果过程控制稳定，数据的波动值就会比较小。这时，数据的信噪比往往也会变得很小。如果用这些数据进行分析，分析结果一般也适合于很小的波动内、只能用来进行微调。这时，即便授权机器进行微调，效果可能也微乎其微。而且，由于数据的信噪比比较小，微调时的系数往往也算不准。

从数据分析的角度看，参数波动范围比较大的时候，往往才有优化的空间。从生产规范性的角度看，这些场景往往是些相对难以规范的场景。比如初级原料的波动、生产的异常、特殊的处理、人为的操作。在这些场景下，数据优化的思路其实特别简单。其基本原理就是：把历史上成功的做法记下来，作为这次操作的参考。当数据积累足够多时，就容易从历史上找到和现在情况差不多的成功案例。但历史上的成功案例和现在的情况可能有所差别，所谓“世界上没有两片完全一样的叶子”。这时，就要对历史的成功做法进行调整和修正，来平衡或者抵消这种差异。本质上讲，这个想法和PDCA循环是一样的；但这个循环可以让机器帮助人来做。我要强调的是：这种做法是具备一般性的：因为这种做法是基于实践的。而实践也反复证明：这种方法往往才是最有效的。我敢负责地说：多个行业都是这么做的。

大家注意到：如果上述逻辑是成立的，数据分析就不必要做得太复杂；复杂的算法往往是没有用的。即便是有用，花费的时间也太长（我就曾经花费了十多年，你承受得起吗？）、代价也太大。只要发挥计算机“记得住”的优势，在这个基础上不断改进就可以了。

<strong>红河谷,红谷软件,智能制造,数字化转型,MES,钢铁,造纸,浦项</strong>